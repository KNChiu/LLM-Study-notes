# Nemotron-4 340B Technical Report

## 1. 模型簡介

### **模型家族**

* Nemotron-4-340B-Base
* Nemotron-4-340B-Instruct
* Nemotron-4-340B-Reward

### 模型價值

* 適用於生成合成數據以訓練較小的語言模型。
* 超過 98% 用於模型校準過程中的數據是透過合成來生成的。
* 開源了合成數據的生成流程。

## 2. 資料與訓練

### **資料組成**

* 涵蓋53種自然語言和43種程式語言。
  * 70% 英文自然語言資料
  * 15% 多語種自然語言資料
  * 15% 程式碼資料
* 高質量數據
  * Llama-2 使用 2T Token ，Llama-3 使用 2T Token&#x20;
  * Nemotron-4 340B Base 只使用 9T Token 高質量數據集

### **訓練過程**

* 訓練資料(9T)
  * 8T Token 用於正式預訓練階段
  * 1T Token 用於持續預訓練階段
* 訓練設備
  * 768個 DGX H100 節點，每個節點包含8個 H100 80GB SXM5 GPU。
* 模型校準
  * 結合人類反饋的強化學習 (RLHF)與直接偏好優化 (DPO)
  * 使模型更好地遵循指令、有效地進行對話和解決問題

### 繼續訓練(**Continued training)**

* 資料分佈 : 在繼續訓練階段中利用兩種不同的資料分佈。
  * 第一種: 將重點放在更高品質的來源上。
  * 第二種: 引入少量問答式，使模型可以更好的面對此類問題，增加來自模型精度較低區域的資料來源
* 訓練階段
  * 這種資料分佈的順序和風格使模型更好地從訓練最後階段引入的數據。

## 3. 模型架構

### **基礎模型架構**:

* 96層Transformer層、隱藏層維度為18432
* 96個注意力頭和8個KV頭
* 序列長度為4096、詞彙量為256,000
* 使用旋轉位置嵌入（RoPE）和SentencePiece標記器

## 4. 模型對比

### Nemotron-4-340B-Base

* **關聯性**: 提供基本的語言理解和生成能力。
* **資料組成**: 70% 英文自然語言資料、15% 多語種自然語言資料、15% 程式碼資料。
* **訓練說明**:&#x20;
  * 使用多種標準化的任務設置進行訓練。
  * 確保評估結果的可比性和可信度。
  * 可能無法完全覆蓋真實世界中的多樣化需求。
* **模型用途**: 各類語言任務，如文本生成、問答系統等，作為其他模型（指導模型和獎勵模型）的基礎。
* **任務說明**:&#x20;
  * MMLU: 測量模型在多領域多任務表現的基準，由大量的多選題組成，涵蓋57個主題。
  * BigBenchHard: 多樣化的挑戰任務，專為超出當前模型能力的任務設計。強調推理和創造能力。
  * ARC-Challenge: 測試模型推理能力的問題集，分為簡單組和挑戰組。

<figure><img src="../../.gitbook/assets/image (47).png" alt="" width="342"><figcaption><p>Nemotron-4-340B-Base</p></figcaption></figure>

### Nemotron-4-340B-Instruct

* **關聯性**: 基於Base模型進行微調，專注於跟隨指令和對話能力。
* **資料組成**: 基礎資料上進行微調，包括人類反饋強化學習（RLHF）和直接偏好優化（DPO）。
* **用途**: 適合於需要準確跟隨指令的任務，如自動客服、虛擬助理等。
* **任務說明**:&#x20;
  * Arena Hard: 是更為嚴苛的即時實際聊天，用於測試模型的即時反應和交互表現。
  * IFEval: 針對自然語言指示的回應能力，評估其指令理解和執行的準確性和效率。
  * AlpacaEval 2.0: 設計為簡化複雜指令，進行快速、自動化、可靠的模型評估。

<figure><img src="../../.gitbook/assets/image (48).png" alt="" width="334"><figcaption><p>Nemotron-4-340B-Instruct</p></figcaption></figure>

### Nemotron-4-340B-Reward

* **關聯性**: 用於評估和提高模型生成內容質量的獎勵模型。
* **資料組成**: 使用大量合成數據進行微調。
* **訓練說明**:&#x20;
  * 訓練10k條人類偏好數據來提高模型的指令遵循能力。
  * 強化模型在多回合對話中的表現。
  * 但偏好數據的質量和多樣性直接影響效果。
* **用途**: 評估和優化模型生成內容的質量。
* **任務說明**:&#x20;
  * Overall: 整體評估包含多項測試工具和數據集，用於綜合評估模型在不同任務和場景下的表現。
  * Chat-Hard: 專注於多輪對話測試，測試更為複雜和多變的對話情境下的模型表現。
  * Safety  安全性測試集專注於模型回答是否安全，避免生成有害內容，並確保在各種情境下的表現符合安全要求。

<figure><img src="../../.gitbook/assets/image (49).png" alt="" width="342"><figcaption><p>Nemotron-4-340B-Reward</p></figcaption></figure>

<figure><img src="../../.gitbook/assets/image (1).png" alt=""><figcaption><p>各任務對比</p></figcaption></figure>

## 5. 訓練方法細節

* **標準化任務設置**: 使用 MMLU (5-shot)、BBH (3-shot) 等標準化任務進行訓練。
* **常識推理**：ARC（25-shot）、Winogrande（5-shot）和 Hellaswag（10-shot）。
* **程式碼**: HumanEval (0-shot)
* **超參數調整**: 調整學習率的斜率和分佈順序，允許模型平穩過渡到最終訓練數據。

## 6. 合成數據生成

### 合成提示生成

* 使用 Mixtral-8x7B-Instruct-v0.1 生成合成提示。
* 任務多樣性（寫作、開放式問答、封閉式問答）
* 主題多樣性（例如詞幹、人文、日常生活）
* 指令多樣性（例如json輸出、特定格式）
* 98%的數據通過生成合成數據來獲得。
* 提供高質量的訓練數據但合成數據的真實性和多樣性仍需進一步驗證。

### 生成流程說明

#### 開放式問答提示

* 收集 3K 個主題。
* 提示產生器產生與對應主題相關的問題來產生開放式問答提示（例如 : 「什麼是機器學習？」）。
* 對於與寫作相關的提示要求將問題細化為更詳細和具體（例如 : 「寫一篇關於機器學習的論文。」）。
* 有關給定主題的某些類型文件的說明。

#### 封閉式問答提示

* 使用 C4 資料集中的文字。
* 對於給定的文檔，限制範圍指令（例如 : 「總結給定的文本」 或 「根據給定的文本，xxx 是什麼？」）。
* 使用手動定義的範本(例如 : 從數學和 Python 程式設計中收集關鍵字)。

<figure><img src="../../.gitbook/assets/image (39).png" alt=""><figcaption><p>合成提示產生</p></figcaption></figure>

### 合成對話生成

* 每個對話包含三個回合(例如 : 「寫一篇關於機器學習的文章。您的答案應該包含三個段落)
* 通過角色扮演和對話歷史設置模擬用戶互動情境(例如 : 「用戶：XXX；助理：XXX；用戶：XXX；」)。
* 對話生成過程複雜度較高需要大量計算資源。
* 利用 Nemotron-4-340B-Reward 來評估對話的質量

### 偏好資料生成

* 使用10K 人工註釋的HelpSteer2 偏好數據來訓練Nemotron-4-340B-Reward。
* 每個提示輸出的多個回應，判斷偏好排名並加上標註(例如 : **已選擇/拒絕**回應)
* 增加偏好數據的多樣性和覆蓋範圍。

### 迭代優化

#### 第一次迭代 (使用 Mixtral-8x7B-Instruct-v0.1)

1. 使用 Mixtral-8x7B-Instruct-v0.1 作為資料生成模型。
2. 產生的資料用於訓練 Nemotron-4-340B-Base (產生 340B-Interm-1-Instruct)
3. 340B-Interm-1-Instruct 超越 Mixtral-8x7B-Instruct-v0.1 。證明可以透過弱監督來激發出強能力。

#### 第二次迭代 (使用 340B-Interm-1-Instruct)

1. 使用 Mixtral-8x7B-Instruct-v0.1 資料訓練的 340B-Interm-1-Instruct 作為資料生成模型。
2. 產生的資料資料用於將 340B-Interm-2-Base 訓練為 340B-Interm-2-Chat

#### 迭代說明

* 當使用相同資料集時，基礎模型越強，產生的指導模型就越強。&#x20;
* 當使用相同的基礎模型時，更高品質的資料導致更強的指導模型。
* 進行多輪資料產生和精煉，不斷提高模型的品質。

<figure><img src="../../.gitbook/assets/image (40).png" alt=""><figcaption></figcaption></figure>

### 合成數據質量控制

* 合成數據的真實性和多樣性仍需進一步驗證。
* 使用Reward模型評估對話質量，過濾低於預定門檻的數據。
* 在提高保留數據的質量時，可能會漏掉一些有價值的數據。
* 在模型可能無法自行完成某些任務產生幻覺，採用人工的範例來提示 LLM 產生各種問題。
* 要求 LLM 做出拒絕回應，收集這些回應並將其與相應的問題配對，訓練模型，使其能夠更好地處理它無法完成的任務。

## 7. 效果評估

### 自動評估(依據數據集)

<figure><img src="../../.gitbook/assets/image (42).png" alt=""><figcaption><p>粗體表示所有模型中得分最高，底線表示開源模型中得分最高</p></figcaption></figure>

### 人為評估(專門註釋團隊)

#### 任務分級

根據10 個不同的任務類別進行6個級別評估，包括5個品質的級別加上1個定義模型完全未能回答的級別。

<figure><img src="../../.gitbook/assets/image (44).png" alt=""><figcaption><p>比較 Nemotron-4-340B-Instruct 與 GPT-4-1106-preview 在十個任務中人為判定</p></figcaption></figure>

#### 人類對生成長度的感知

<figure><img src="../../.gitbook/assets/image (45).png" alt=""><figcaption><p>下劃線表示感知適當長度率較高的模型</p></figcaption></figure>

### **安全評估**

<figure><img src="../../.gitbook/assets/image (46).png" alt=""><figcaption><p>AEGIS 安全評估中不安全回應佔比，越低越好</p></figcaption></figure>

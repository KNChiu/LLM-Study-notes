---
description: Synthetic Data Generation with Large Language Models for Text
---

# 使用大型文字語言模型產生合成數據

## 1. Introduction

### 合成數據的需求與研究背景

* **高質量的訓練數據的重要性**
  * 高質量的訓練數據對於文本分類模型的性能至關重要。
  * 然而收集和整理這些數據既耗費時間又昂貴。
* **研究目的**
  * 探討是否可以透過大型語言模型（LLMs）生成高效的合成數據來替代傳統的數據收集方法。
  * 希望能減少數據收集的成本和時間。
* **潛在問題與挑戰**
  * 雖然生成的合成數據可以大幅降低成本，但其效果可能不如實際數據。
  * 合成數據在不同任務間的應用效果存在變異，這也是需要克服的一大挑戰。

## 2. Related Work

### 生成式AI與大型語言模型

* 依賴大型語言模型，如GPT-3.5 Turbo生成高質量的文本數據。
  * 在生成類人類文本方面表現優異且涵蓋多種應用，例如科學數據生成和程式生成。
  * 但在特定領域的專業知識上有所不足。

## 3. Methodology

### 零樣本數據生成

* 零樣本數據生成是在無任何真實數據的前提下，透過自定義提示生成合成數據。
  * 不需要預先存在的數據，適用於新領域。
  * 生成數據的多樣性和實際效能可能較低。

### 少樣本數據生成

* 使用少量實際數據作為示例，輔助大型語言模型生成合成數據。
  * 生成的數據更具有多樣性和實效性。
  * 但是仍需要一些真實數據作為參考。

## 4. Evaluation I: Comparison Across Different Types of Tasks

### 主觀性對數據效用的影響

* 主觀性高的任務需要深度理解語境和情感，這超出了目前LLMs的能力，導致其生成的數據在捕捉語言豐富性和細微差異方面表現不足
  * 在低主觀性任務中，合成數據的效能可以接近真實數據。
  * 在高主觀性任務中，合成數據效能顯著下降。

### 合成數據在不同任務上的效用

* 過實驗評估LLM生成的合成數據在10種不同類型的文本分類任務中的效用，採用比較方法，每位參與者對10個任務進行主觀判斷。
  * 隨機抽取的一對文本分類任務，根據任務描述、標籤描述和示例來判定哪個任務更客觀。
  * 總共獲得了540個成對主觀比較，來確定每個任務的主觀性水平並進行排名。
  * 最終得到的任務主觀性排名結果如下，反映了不同文本分類任務的主觀性水平差異。

<figure><img src="../../../.gitbook/assets/image.png" alt=""><figcaption><p>在「主觀性」欄中，「⋆」符號越多，表示任務主觀性程度越高。</p></figcaption></figure>



## 5. Evaluation II: Comparison Across Different Task Instances

### 主觀性程度的實例分析

* 模型在低主觀性實例上的表現優於高主觀性實例，這表明即便在相同的分類任務中，實例的主觀性也會影響模型的效能。
* 針對主觀性實例進行更準確的性能預測和調整。
* 高主觀性實例的準確分類仍然是挑戰。

## 6. Discussions

### 少樣本數據增強

* 當少量真實數據和少樣本合成數據結合使用時，模型性能通常優於單純使用真實數據或合成數據
  * 結合真實數據和合成數據提升模型效能。
  * 需額外處理合成數據和真實數據的整合問題。

### 未來研究方向

* 探索如何利用人類智慧（例如反饋或直接介入）增加數據多樣性，以及更好地辨識和生成最具信息性的數據實例。
  * 增加數據多樣性，提高模型效能。
  * 需要更複雜的生成策略和人類干預。

## 7. Conclusion

* 總結研究發現與意涵。
